<!--
  Copyright 2018 The Distill Template Authors
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at
       http://www.apache.org/licenses/LICENSE-2.0
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!doctype html>

<style>
.base-grid,
.n-header,
.n-byline,
.n-title,
.n-article,
.n-footer {
    display: grid;
    justify-items: stretch;
    grid-template-columns: [screen-start] 8px [page-start kicker-start text-start gutter-start middle-start] 1fr 1fr 1fr 1fr 1fr 1fr 1fr 1fr [text-end page-end gutter-end kicker-end middle-end] 8px [screen-end];
    grid-column-gap: 8px;
}

.grid {
  display: grid;
  grid-column-gap: 8px;
}

@media(min-width: 768px) {
    .base-grid,
    .n-header,
    .n-byline,
    .n-title,
    .n-article,
    .n-footer {
        display: grid;
        justify-items: stretch;
        grid-template-columns: [screen-start] 1fr [page-start kicker-start middle-start text-start] 45px 45px 45px 45px 45px 45px 45px 45px [ kicker-end text-end gutter-start] 45px [middle-end] 45px [page-end gutter-end] 1fr [screen-end];
        grid-column-gap: 16px;
    }

    .grid {
        grid-column-gap: 16px;
    }
}

@media(min-width: 1000px) {
    .base-grid,
    .n-header,
    .n-byline,
    .n-title,
    .n-article,
    .n-footer {
        display: grid;
        justify-items: stretch;
        grid-template-columns: [screen-start] 1fr [page-start kicker-start] 50px [middle-start] 50px [text-start kicker-end] 50px 50px 50px 50px 50px 50px 50px 50px [text-end gutter-start] 50px [middle-end] 50px [page-end gutter-end] 1fr [screen-end];
        grid-column-gap: 16px;
    }

    .grid {
        grid-column-gap: 16px;
    }
}

@media (min-width: 1180px) {
    .base-grid,
    .n-header,
    .n-byline,
    .n-title,
    .n-article,
    .n-footer {
        display: grid;
        justify-items: stretch;
        grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
        grid-column-gap: 32px;
    }
    .grid {
        grid-column-gap: 32px;
    }

}

.base-grid {
  grid-column: screen;
}

/* default grid column assignments */
.n-title > *  {
  grid-column: text;
}

.n-article > *  {
  grid-column: text;
}

.n-title {
    padding: 4rem 0 0.5rem;
}

.l-page {
    grid-column: page;
}

.l-article {
    grid-column: text;
}

p {
  margin-top: 0;
  margin-bottom: 1em;
}


.pixelated {
    image-rendering: pixelated;
}

strong {
    font-weight: 600;
}

/*------------------------------------------------------------------*/
/* title */
.n-title h1 {
    font-family: "Barlow",system-ui,Arial,sans-serif;
    color:#082333;
    grid-column: text;
    font-size: 26px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
    text-align: center;
}

@media (min-width: 768px) {
    .n-title h1 {
        font-size: 50px;
    }
}


.n-byline {
  contain: style;
  overflow: hidden;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  font-size: 0.8rem;
  line-height: 1.8em;
  padding: 1.5rem 0;
  min-height: 1.8em;
}

.n-byline .byline {
  grid-column: text;
}

.byline {
    grid-template-columns: 1fr 1fr 1fr 1fr;
}

.grid {
    display: grid;
    grid-column-gap: 8px;
}

@media (min-width: 768px) {
.grid {
    grid-column-gap: 16px;
}
}

.n-byline p {
  margin: 0;
}

.n-byline h3 {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    margin: 0;
    text-transform: uppercase;
}
.n-byline .authors-affiliations {
  grid-column-end: span 2;
  grid-template-columns: 1fr 1fr;
}

ul.authors {
    list-style-type: none;
    padding: 0;
    margin: 0;
    text-align: center;
}
ul.authors li {
    padding: 0 0.5rem;
    display: inline-block;
}

ul.authors sup {
    color: rgb(126,126,126);
}

ul.authors.affiliations  {
    margin-top: 0.5rem;
}

ul.authors.affiliations li {
    color: rgb(126,126,126);
}


</style>
<head>
    <title>Zero Shot Image Restoration Using Denoising Diffusion Null-Space Model</title>
    <script src="template.v2.js"></script>
    <meta property="og:title" content="Zero Shot Image Restoration Using Denoising Diffusion Null-Space Model">
    <meta property="og:type" content="website">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <meta charset="utf8">
</head>

<body>
  <div class="n-title">
   <h1>
    Zero Shot Image Restoration Using Denoising Diffusion Null-Space Model
   </h1>
   <p style="text-align: center"> State-of-the-art performance in linear image inverse problems. </p>
   <p style="text-align: center"> <a href = "https://arxiv.org/abs/2104.07636" style="text-decoration:none; color: inherit;"><b>Paper</b></a> </p>
  </div>
  <div class="n-byline">
   <div class="byline">
    <ul class="authors">
     <li>
      <a href = "https://yinhuai.github.io/" style="text-decoration:none; color: inherit;">Yinhuai Wang</a>
     </li>
     <li>
      <a href = "https://jiwen.github.io/" style="text-decoration:none; color: inherit;">Jiwen Yu</a>
     </li>
     <li>
      <a href = "https://jianzhang.tech/" style="text-decoration:none; color: inherit;">Jian Zhang</a>
     </li>
    </ul>
    <ul class="authors affiliations">
     <li>
      <a href = "https://www.ece.pku.edu.cn/en/" style="text-decoration:none; color: inherit;">Peking University, SECE</a>
     </li>
     <li>
      <a href = "https://www.ece.pku.edu.cn/en/" style="text-decoration:none; color: inherit;">PCL</a>
     </li>
    </ul>
   </div>
  </div>
  <d-article>
    <video controls autoplay loop width="1080" height="560" style="object-fit: contain;grid-column: page;">
     <source src="images/super_res_movie.m4v" type="video/mp4">
     </video>
    <h3>Introduction</h3>
    <p>
      Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators. 
      In this work, we propose the <b>D</b>enoising <b>D</b>iffusion <b>N</b>ull-Space <b>M</b>odel (<b>DDNM</b>), a novel zero-shot framework for arbitrary linear IR problems,
      including but not limited to image super-resolution, colorization, inpainting, compressed sensing, and deblurring. 
      DDNM only needs a pre-trained off-the-shelf diffusion model as the generative prior, without any extra training or network modifications. 
      By refining only the null-space contents during the reverse diffusion process, we can yield diverse results satisfying both data consistency and realness. 
      We further propose an enhanced and robust version, dubbed DDNM+, to support noisy restoration and improve restoration quality for hard tasks. 
      Our experiments on several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot IR methods. 
      We also demonstrate that DDNM+ can solve complex real-world applications, e.g., old photo restoration. 
    </p>
    <h3>Range-Null Space Decomposition (RND)</h3>
    <p>
      RND is a well-known concept in the field of linear algebra. For linear inverse problems, the lost information is exactly the Null-space while the kept information is exactly the range-space. If we know the degradation operator, the range-space can be analytically solved, by which we can yield fully consistent results. Here's an example.
    </p>
    <figure  style="grid-column: text">
        <img src="images/rnd_colorization.png" style="width: 100%; margin-top: 1rem;display: block; margin-left: auto; margin-right: auto;"/>
          <figcaption >  <b>RND for colorization task</b>: y is the input image, xr is a raw result predicted by the network. It is obvious that xr is not consistent to y. But after a simple RND operation, we can yield a fully consistent colorization result.  </figcaption>
    </figure>


    <p>
      <h3>RND for Diffusion Models</h3>
      <p>
        Diffusion models use a denoiser to remove the noise and generate the next state. This actually yields a clean image x0|t at each step.
      </p>
      <figure  style="grid-column: text">
          <img src="images/ddpm.png" style="width: 100%; margin-top: 1rem;display: block; margin-left: auto; margin-right: auto;"/>
          <figcaption style="display:flex; justify-content: center"> Original DDPM reverse diffusion process.  </figcaption>
      </figure>
      <p>
        We apply RND to each clean image x0|t to yield consistent estimation.
      </p>
      <figure  style="grid-column: text">
          <img src="images/ddnm.png" style="width: 100%; margin-top: 1rem;display: block; margin-left: auto; margin-right: auto;"/>
          <figcaption style="display:flex; justify-content: center"> DDNM reverse diffusion process. We apply RND to each clean image x0|t.  </figcaption>
      </figure>
      <p>
        By changing the degradation A, we can use a pretrained diffusion model to solve arbitrary linear inverse problems, without any training or optimization. Below we visualize the intermediate results of DDNM.
      </p>
      <video controls autoplay loop width="1080" height="560" style="object-fit: contain;grid-column: page;">
      <source src="images/super_res_movie.m4v" type="video/mp4">
      </video>
    
      <h3>DDNM for Noisy Restoration Tasks</h3>
      <p>
        DDNM provide a elegant solution for general linear image restoration problems y=Ax. However, it can not handle noisy situations where y=Ax+n. We provide a simple but effective solution to solve the noise. We add two parameters Σt and Φt to make sure the total noise invariant while maximizing the range-space preservation.    
      </p>
      <figure  style="grid-column: text">
          <img src="images/ddnm+.png" style="width: 100%; margin-top: 1rem;display: block; margin-left: auto; margin-right: auto;"/>
          <figcaption style="display:flex; justify-content: center"> DDNM+ reverse diffusion process. Σt and Φt make sure the total noise level is the same as the original diffusion model.  </figcaption>
      </figure>
    
<h3>Related projects</h3>
<ul>
  <li><a href="https://cascaded-diffusion.github.io/">Cascaded Diffusion Models</a></li>
  <li><a href="https://iterative-refinement.github.io/palette/">Palette: Image-to-Image Diffusion Models</a></li>
</ul>
      

<h3>Citation</h3>
<p>
  For more details and additional results, <a href="https://arxiv.org/abs/2104.07636">read the full paper</a>.
</p>
<code>
  @article{saharia2021image,
  <div style="padding-left: 5%; margin: 0">
    title={Image super-resolution via iterative refinement},<br/>
    author={Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J and Norouzi, Mohammad},<br/>
    journal={arXiv:2104.07636},<br/>
    year={2021}}<br/>
  </div>
  }<br/>
</code>
<span style="margin-bottom: 10%"></span>
</d-article>


</body>
